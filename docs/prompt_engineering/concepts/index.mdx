# Concepts

Prompt engineering is one the core pillars of LangSmith.
While traditional software application are built by writing code, AI applications often involve a good amount of writing prompts.
We aim to make this as easy possible by providing a set of tools designed to enable and facilitate prompt engineering.

## Why prompt engineering?

A prompt sets the stage for the model, like an audience member at an improv show directing the actor's next performance - it guides the model's
behavior without changing its underlying capabilities. Just as telling an actor to "be a pirate" determines how they act,
a prompt provides instructions, examples, and context that shape how the model responds.

Prompt engineering is important because it allows you to change the way the model behaves.
While there are other ways to change the model's behavior (like fine-tuning), prompt engineering is usually the simplest to get started with
and often provides the highest ROI.

We often see that prompt engineering is multi-disciplinary.
Sometimes the best prompt engineer is not the software engineer who is building the application, but rather the product manager
or another domain expert.
It is important to have the proper tooling and infrastructure to support this cross-disciplinary building.

## Prompts vs Prompt Templates

Although we often use these terms interchangably, it is important to understand the difference between "prompts" and "prompt templates".

Prompts refer to the messages that are passed into the language model.

Prompt Templates refer to a way of formatting information to get that prompt to hold the information that you want. Prompt templates
can include variables for few shot examples, outside context, or any other external data that is needed in your prompt.

[image]

## Prompts in LangSmith

You can store and version prompts templates in LangSmith.
There are few key aspects of a prompt template to understand.

### Messages vs Instruction

A message can be an instruction (passed as a single string) or a list of messages. Passing a list of messages
can help the model learn neccessary context, but is not always needed if the task is straightforward enough.

### F-string vs mustache

You can format your prompt with input variables using either [f-string](https://realpython.com/python-f-strings/) or [mustache](https://mustache.github.io/mustache.5.html) format. Here is an example prompt
with f-string format:

```python
Hello, {name}!
```

And here is one with mustache:

```python
Hello, {{name}}!
```

:::tip Mustache format
Mustache format gives your more flexbility around conditional variables, loops, and nested keys.
Read [the documentation](https://mustache.github.io/mustache.5.html)
:::

### Tools

Tools are interfaces the LLM can use to interact with the outside world. Tools consist of a name, description, 
and JSON schema of arguments used to call the tool.

### Structured Output

Structured output is a feature of most state of the art LLMs, wherein instead of producing raw text as output they
stick to a specified schema.

### Model

Optionally, you can store a model configuration alongside a prompt template. Saving the right model settings alongside
the right prompt is the best way to improve the performance of your LLM application.

## Prompt Versioning

Verisioning is a key part of iterating and collaborating on your different prompts.

### Revisions
### Tags

## Prompt Playground

The prompt playground makes the process of iterating and testing your prompts seamless. You can enter the playground from the sidebar:

![](./static/enter_the_playground.gif)

How to use: pass in data for the specified variables

GIF/SCREENSHOT

You can change the model easily in the playground:

![](./static/change_model_in_playground.gif)

In addition, you can provide your model with different tools that it can call:

![](./static/add_tools_playground.gif)

You can also add strctured output so your model behaves in a more constrained manner:

![](./static/add_structured_output_playground.gif)

Once you have crafted the perfect prompt, you can save it to the hub for all your teammates to see and work with:

![](./static/save_prompt_in_playground.gif)

## Testing multiple prompts

You can add more prompts to your playground to easily compare outputs and decide which version is better:

![](./static/add_prompt_to_playground.gif)

## Testing over a dataset

To test over a dataset, you simply select the dataset from the top right and press Start. You can modify whether the results
are streamed back as well as how many repitions there are in the test.

![](./static/test_over_dataset_in_playground.gif)

You can click on the "View Experiment" button to dive deeper into the results of the test:

![](./static/view_experiment_results_playground.gif)

## Prompt Canvas

The prompt canvas makes it easy to edit a prompt with the help of an LLM. This allows you to iterate
faster on long prompts and also makes it easier to make overarching stylisting or tonal changes to your prompt.
You can enter the promp canvas by clicking the glowing wand over any message in your prompt:

![](./static/prompt_canvas_open.gif)

### How to use: chat sidebar

You can use the chat sidebar to ask questions about your prompt. While chatting, the agent won't make any edits
to the prompt itself unless asked to do so:

![](./static/prompt_canvas_chat_window.gif)

### How to use: write directly

When asked for a rewrite a new version of the prompt will be streamed back, with an explanation in the chat sidebar:

![](./static/prompt_canvas_rewrite.gif)

### Quick actions

There are quick actions to change the reading level or length of the prompt with a single mouse click:

![](./static/prompt_canvas_quick_actions.gif)

### Custom quick actions

You can also save your own custom quick actions, for ease of use across all the prompts you are working on in LangSmith:

![](./static/prompt_canvas_custom_quick_action.gif)

### Diffing

You can also see the specific differences between each version of your prompt by selecting the diff slider in the top right of the canvas:

![](./static/prompt_canvas_diff.gif)

### Saving and using

Lastly, you can save the prompt you have created in the canvas by clicking the "Use this Version" button in the bottom right:

![](./static/prompt_canvas_save.gif)